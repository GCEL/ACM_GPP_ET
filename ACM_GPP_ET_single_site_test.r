###
## Define useful functions
###

closest2d <- function (id,lat,long,lat_in,long_in,nos_dim) {

    ###
    ## function to return x,y coordinate from an array which is nearest to a provided lat / long value
    ###
  
    ###
    ## Define arguments
  
    # id = location from the lat_in and long_in vector you wish to find (can be equal to 1 if *_in are scalers)
    # lat = array / vector of latitudes (-90 -> 90) to search for nearest location
    # long = array / vector of longitudes (-180 -> 180) to search for nearest location
    # lat_in = scaler / vector of latitudes for locations you wish to find
    # long_in = scaler / vector of longitudes for locations you wish to find
    # nos_dim = defines the way in which the searchable lat / long information has been provided. 
    #           See code below for definitions

    # extract needed lat / long 
    lat1=lat_in[id] ; long1=long_in[id]

    # calculate the distance between two points by Spherical law of the cosine
    # mean radius of earth in km
    R=6371  # 6378137 m (R source equitorial)
    # convert degrees to radians
    deg_to_rad = pi/180
    
    # check lat / long system has been provided in the correct bounds
    if (length(which(as.vector(long) > 180)) > 1) {stop("Input error closest2d: longitude should be -180 to +180")}

    if (nos_dim == 1) {

      	## lat long are in single vectors repeating i.e. lat[1:10]=89.9,89.9,89.9... ; long[1:10]=-180,-160,-140....

      	# loop through to find the smallest distance
      	d_old=1e6
      	# check for locations which exactly coincide, complete calculatuion and finally remove NaN generated by value "1"
      	d = acos(sin(lat1*deg_to_rad)*sin(lat*deg_to_rad)+cos(lat1*deg_to_rad)*cos(lat*deg_to_rad)*cos((long*deg_to_rad)-(long1*deg_to_rad)))*R
      	match = which(is.na(d) == TRUE) ; d[match] = 0 ; d = pmax(1e-6,d,na.rm=TRUE)
      	output=which(d == min(d))[1] ; d_old=d[output] ; rm(d_old)
      	
    } else if (nos_dim == 2) {

      	## lat and long are in two - dimensional arrays which co-varying 
      	# loop through to find the smallest distance
      	d = sin(lat1*deg_to_rad)*sin(as.vector(lat)*deg_to_rad)+cos(lat1*deg_to_rad)*cos(as.vector(lat)*deg_to_rad)*cos((as.vector(long)*deg_to_rad)-(long1*deg_to_rad))
      	# check for locations which exactly coincide, complete calculatuion and finally remove NaN generated by value "1"
        d = acos(d)*R ; match = which(is.na(d) == TRUE) ; d[match] = 0
	    	i=ceiling(which(d == min(d))/dim(lat)[1]) ; j=which(d == min(d))-floor(which(d == min(d))/dim(lat)[1])*dim(lat)[1]
	      output = list(j[1],i[1]) ; rm(i,j)
	      
    } else if (nos_dim == 3) {
      
      	## lat and long are in two 1-dimensional vectors but co-varying as in cartesian co-ordinates
      	# loop through to find the smallest distance
      	d_old=1e6
      	for (j in seq(1, length(lat))) {
      	    # convert all to radians
      	    d = acos(sin(lat1*deg_to_rad)*sin(lat[j]*deg_to_rad)+cos(lat1*deg_to_rad)*cos(lat[j]*deg_to_rad)*cos((long*deg_to_rad)-(long1*deg_to_rad)))*R
      	    # is the current test location a closer fit?
      	    if (min(d) < d_old) {
      	        # if so great we must store it and continue...
            		possible_i = which(d == min(d))
            		# ...assuming that there is a single location which fits the minima
            		if (length(possible_i) > 1 & possible_i[1] == 1 & possible_i[length(possible_i)] == length(long)) {
            		    # arbitarily assume the final value in the array is the one we will go with
            		    possible_i = possible_i[which(long[possible_i] == long1)]
            		} # multiple fits
            		# store minima to output
            		output = list(possible_i[1],j) ; d_old=min(d)
      	    } # min(d) < d_old
      	} # j loop
      	rm(i,d_old)
      	
    } # nos_dim criteron

    # clean up
    rm(d,R,lat1,long1) 
    # return to the user
    return(output)

} # end of function

###
## Create needed ACM_GPP_ET shared object

# set to the working directory for your analysis, 
# NOTE 1: this script assumes that within this directory contains a "src" directory containing the ACM-GPP-ET model
# NOTE 2: this script assumes that within this directory contains a "input" directory containing the *csv file inputs
setwd("/home/lsmallma/WORK/GREENHOUSE/models/ACM_GPP_ET/") ; wkdir = getwd()
# compile fortran code into a shared object which R can load as a function
system("gfortran ./src/ACM_GPP_ET.f90 ./src/ACM_GPP_ET_R_interface.f90 -o ./src/acm_gpp_et.so -fPIC -shared")
system("mv ./src/acm_gpp_et.so .")

###
## Check how many site files we have to work with

# search for files in our assumed inputs directory
files_to_do = list.files("./inputs", full.names=TRUE)
# filter for those which are *csv
files_to_do = files_to_do[grepl("csv",files_to_do)]
# filter for those which have correct prefix "ACM_GPP_ET_"
files_to_do = files_to_do[grepl("ACM_GPP_ET_",files_to_do)]
# read in the first file to extract some useful timing information
drivers = read.csv(files_to_do[1],header=TRUE, skip=1)
# how many time steps in the analysis?
# NOTE: this script assumes that for any given analysis each site simulates the same time period
nos_steps = dim(drivers)[1]

###
## Define our output variables based on the grid of the CARDAMOM analysis we are borrowing

timeseries_lai = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_root = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_gpp = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_transpiration = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_wetcanopyevap = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_soilevaporation = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_soilwatermm = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_WUE = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_wSWP = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_runoffmm = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_drainagemm = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_LWP = array(NA, dim=c(length(files_to_do),nos_steps))
timeseries_ci = array(NA, dim=c(length(files_to_do),nos_steps))

###
## Some ACM_GPP_ET parameters

output_dim=11 ; nofluxes = 8 ; nopools = 1 ; nopars = 5 ; nos_iter = 1

# begin looping through each of the files
for (n in seq(1, length(files_to_do))) {

    # read first line from the input file to get the location information
    lat = readLines(files_to_do[n], n = 1) # this comes as a text vector
    # split based on presence of "," and take the second component (should be the number)
    # and convert into a number...Latitude (degrees)
    lat = as.numeric(unlist(strsplit(lat,","))[2])
  
    # read in the current sites driver file
    drivers = read.csv(files_to_do[n], header=TRUE, skip=1)
    
    # keep the user up to date on the progress
    if (n%%100 == 0){print(paste("...beginning site:",n," of ",length(files_to_do), sep=""))}

    # define the met drivers array and load information from the input file
    met=array(-9999,dim=c(length(drivers$min_T_oC),12))

    ###
    ## Extract meteorological drivers
    
    met[,1] = 1:length(drivers$min_T_oC)  # day of analysis
    met[,2] = drivers$min_T_oC  # min temperature (oC)
    met[,3] = drivers$max_T_oC  # max temperature (oC)
    met[,4] = drivers$swrad_MJ_day  # SW Radiation (MJ.m-2.day-1)
    if (length(which(names(drivers) == "co2")) > 0) {
        # if local CO2 data available use it...
        met[,5] = drivers$co2  # CO2 ppm
    } else {
        # ...if not assume global mean
        met[,5] = 400  # CO2 ppm
    } # CO2 present?
    met[,6] = drivers$doy  # day of year
    met[,7] = drivers$rainfall_mmday / (24*60*60)  # rainfall (kg.m-2.day-1 -> kg.m-2.s-1)
    if (length(which(names(drivers) == "avg_T_oC")) > 0) {
        # if local average temperature data available use it...
        met[,8] = drivers$avg_T_oC # avg temperature (oC)
    } else {
        # ...if not assume average of max / min
        met[,8] = 0.5*(drivers$max_T_oC+drivers$min_T_oC) # avg temperature (oC)
    } # avg_T_oC present?
    if (length(which(names(drivers) == "wind_ms")) > 0) {
        # if local average temperature data available use it...
        met[,9] = drivers$wind_ms # avg wind speed (m.s-1)
    } else {
        # ...if not assume global mean wind speed (CRU 1960-1990; New et al., 2001)
        met[,9] = 3.2 # avg wind speed (m.s-1)
    } # wind_ms present?
    met[,10]= drivers$VPD_kPa*1000 # avg VPD (kPa)

    ###
    ## Extract biophysical drivers
    
    met[,11]= drivers$lai # LAI (m2/m2)
    if (length(which(names(drivers) == "roots")) > 0) {
        # if local average temperature data available use it...
        met[,12] = drivers$root # root C stocks (gC/m2)
    } else {
        # ...if not then assume 1:1 fine root to foliar mass. 
        # NOTE: 80 gC/m2 is global mean leaf carbon per unit leaf area
        met[,12] = drivers$lai*80 # root C stocks
    }

    # Some biogeochemical / biogeophysical parameters
    parameters = array(NA, dim=c(nopars,nos_iter))
    parameters[1,] = 1.89  # foliar N (gN.m-2)
    parameters[2,] = -9999 # min leaf water potential (MPa)
    parameters[3,] = 100   # root biomass needed to reach 50 % depth
    parameters[4,] = 2.0   # max root depth (m)
    parameters[5,] = 9     # canopy height (m)

    # Load soil textural information
    # c(top_sand,bottom_sand,top_clay,bottom_clay) # provide as %
    soil_info=c(40,40,15,15)

    # If the model has not been loaded into R memory do so now!
    if (is.loaded("racmgppet") == FALSE) { dyn.load("./acm_gpp_et.so") }
    # call the loaded ACM-GPP-ET model, written in Fortran
    # NOTE: arguments using this interface must have accurately defined dimensions, precision and contain no NaN or Inf values
    tmp=.Fortran("racmgppet",output_dim=as.integer(output_dim),met=as.double(t(met)),pars=as.double(parameters)
                            ,out_var=as.double(array(0,dim=c(nos_iter,(dim(met)[1]),output_dim)))
                            ,lat=as.double(lat),nopars=as.integer(nopars),nomet=as.integer(dim(met)[2])
                            ,nofluxes=as.integer(nofluxes),nopools=as.integer(nopools),nodays=as.integer(dim(met)[1])
                            ,deltat=as.double(array(0,dim=c(as.integer(dim(met)[1])))),nos_iter=as.integer(nos_iter)
                            ,soil_frac_clay=as.double(array(c(soil_info[3],soil_info[3],soil_info[4],soil_info[4]),dim=c(4)))
                            ,soil_frac_sand=as.double(array(c(soil_info[1],soil_info[1],soil_info[2],soil_info[2]),dim=c(4))) )
    # extract output from the analysis
    output=tmp$out_var ; output=array(output, dim=c(nos_iter,(dim(met)[1]),output_dim))
    rm(tmp) ; gc()

    # assign outputs to out final grids
    timeseries_lai[n,] = (output[,1:dim(met)[1],1])             # lai (m2/m2)
    timeseries_root[n,] = met[,12]                              # root (gC/m2)
    timeseries_gpp[n,] = (output[,1:dim(met)[1],2])             # GPP (gC.m-2.day-1)
    timeseries_transpiration[n,] = (output[,1:dim(met)[1],3])   # transpiration (kg.m-2.day-1)
    timeseries_wetcanopyevap[n,] = (output[,1:dim(met)[1],4])   # wetcanopy evaporation (kg.m-2.day-1)
    timeseries_soilevaporation[n,] = (output[,1:dim(met)[1],5]) # soil evaporation (kg.m-2.day-1)
    timeseries_wSWP[n,] = (output[,1:dim(met)[1],6])            # weighted soil water potential (MPa)
    timeseries_soilwatermm[n,] = (output[,1:dim(met)[1],7])     # water in top soil (0-10cm; kgH2O/m2)n
    timeseries_runoffmm[n,] = (output[,1:dim(met)[1],8])        # surface runoff (mm)
    timeseries_drainagemm[n,] = (output[,1:dim(met)[1],9])      # drainage / underflow from bottom of soil column (mm)
    timeseries_LWP[n,] = (output[,1:dim(met)[1],10])            # mean LWP (MPa)
    timeseries_ci[n,] = (output[,1:dim(met)[1],11])             # internal CO2 concentration (umol/mol)

} # loop through files_to_do

###
## Save output to .RData binary file format for later analysis

units=c("LAI = m2/m2","Roots = gC/m2","Water use efficiency (WUE) = gC/kgH2O"
       ,"GPP = gC/m2/day","All water fluxes = kgH2O/m2/day"
       ,"mean_soilwatermm = kg/m2","All soil water potentials (SWP) = MPa")

# Save output for later use
acm_gpp_et_output = list(    units = units,
                              site = files_to_do,
                    timeseries_lai = timeseries_lai,
                   timeseries_root = timeseries_root,
                    timeseries_gpp = timeseries_gpp,
          timeseries_transpiration = timeseries_transpiration,
          timeseries_wetcanopyevap = timeseries_wetcanopyevap,
        timeseries_soilevaporation = timeseries_soilevaporation,
            timeseries_soilwatermm = timeseries_soilwatermm,
                    timeseries_WUE = timeseries_WUE,
                   timeseries_wSWP = timeseries_wSWP,
               timeseries_runoffmm = timeseries_runoffmm,
             timeseries_drainagemm = timeseries_drainagemm,
                    timeseries_LWP = timeseries_LWP,
                     timeseries_ci = timeseries_ci)

# Now save the file
save(acm_gpp_et_output, file="./outputs/ACM_GPP_ET_test_output.RData")

###
## Generate simple plots for the first two sites

if (n > 1) {par(mfrow=c(2,4), mar = c(4,4,3,1), omi=c(0.1,0.1,0.1,0.1))} else {par(mfrow=c(2,2), mar = c(4,4,3,1), omi=c(0.1,0.1,0.1,0.1))}
plot(timeseries_lai[1,]~seq(1,length(drivers$doy)), ylab="LAI", xlab="Day of simulation")
plot(timeseries_gpp[1,]~seq(1,length(drivers$doy)), ylab="GPP", xlab="Day of simulation")
plot(timeseries_transpiration[1,]~seq(1,length(drivers$doy)), ylab="Transpiration", xlab="Day of simulation")
plot(timeseries_soilwatermm[1,]~seq(1,length(drivers$doy)), ylab="Top soil water (mm)", xlab="Day of simulation")
if (n > 1) {
    plot(timeseries_lai[n,]~seq(1,length(drivers$doy)), ylab="LAI", xlab="Day of simulation")
    plot(timeseries_gpp[n,]~seq(1,length(drivers$doy)), ylab="GPP", xlab="Day of simulation")
    plot(timeseries_transpiration[n,]~seq(1,length(drivers$doy)), ylab="Transpiration", xlab="Day of simulation")
    plot(timeseries_soilwatermm[n,]~seq(1,length(drivers$doy)), ylab="Top soil water (mm)", xlab="Day of simulation")
} # n > 1
